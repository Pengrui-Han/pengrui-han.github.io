<!DOCTYPE HTML>
<html lang="en">

<head>    
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0B5LHBSZYY"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0B5LHBSZYY');
  </script>

  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Pengrui Han</title>

  <meta name="author" content="Pengrui Han">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="logo" sizes="180x180" href="images/logo.png">
  <link rel="apple-touch-icon" sizes="180x180" href="images/logo.png">
  <link rel="icon" type="image/png" sizes="32x32" href="images/logo.png">
  <link rel="icon" type="image/png" sizes="16x16" href="images/logo_1.png">
  <link rel="manifest" href="images/site.webmanifest">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
<meta name="google-site-verification" content="SppVkSFcpllgYfMj_yChDn5QreKfTWW1_cEwRTvVBMY" />
</head>

<body>
  <table style="width:100%;max-width:1050px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:1.5%;width:70%;vertical-align:middle">
              <p style="text-align:center">
                <name>Pengrui Han (Barry)</name>
              </p>
              <p>   I am currently in the MSCS program at <b>UIUC</b>, advised by Prof. <a href="https://cs.stanford.edu/~jiaxuan/"> Jiaxuan You</a>. 
                I am also a researcher in the <b>MIT Brain and Cognitive Sciences</b> department, working with Prof. 
                <a href="https://www.evlab.mit.edu/">Evelina Fedorenko</a> and Dr. 
                <a href="https://scholar.google.com/citations?user=Iwm9mC0AAAAJ&hl=en&oi=ao">Andrea de Varda</a> in the <b>EvLab</b>. 
                I received my B.A. in Mathematics and Computer Science from <a href="https://www.carleton.edu/"> Carleton College</a>, a leading liberal arts college in the US.
                During my undergrad, I was fortunate to work with Prof.
                <a href="http://tensorlab.cms.caltech.edu/users/anima/"> Anima Anandkumar</a> and Dr. 
                <a href="http://www.rkocielnik.com/">Rafa≈Ç Kocielnik</a> in the <b>Anima AI+Science Lab</b> at <b>Caltech</b>.
                I also previously interned at <b>NVIDIA</b>.


    <!-- <p>
      <strong style="color: red;">I am currently applying for Ph.D. programs in Computer Science for the 2024‚Äì25 cycle.</strong>
  </p> -->


    <!-- I am a research intern at <strong>NVIDIA</strong> <a href="https://research.nvidia.com/labs/gear/">GEAR lab</a>, working with Dr. <a href="https://jimfan.me/">Jim Fan</a>.    -->
              </p>
              <p style="text-align:center">
               Èü©ËäÉÁùø &nbsp/&nbsp
                <a target="_blank" href="mailto:phan3@mit.edu">Email</a> &nbsp/&nbsp
                <!-- <a target="_blank" href="data/CV___Peiyang_Song.pdf">CV</a> &nbsp/&nbsp -->
                <a target="_blank"href="https://scholar.google.com/citations?user=ebKJrBcAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a target="_blank" href="https://github.com/Pengrui-Han">GitHub</a> &nbsp/&nbsp
		<a target="_blank" href="https://www.linkedin.com/in/pengrui-han-barry-17167b227/">LinkedIn</a> &nbsp/&nbsp
		<a target="_blank" href="https://x.com/Barry_Han_PR">Twitter</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/Pengrui_Han.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/Pengrui_Han.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
	<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
	      <p>
  <b>[Jan 2026]</b>  Our paper <a href="https://openreview.net/forum?id=hsgMn4KBFG">Large Language Model Reasoning Failures</a> is accepted to TMLR with a <strong>Survey Certificate</strong>.<br>
  <b>[Dec 2025]</b>  We released our paper on <a href="https://arxiv.org/abs/2512.16301">Adaptation of Agentic AI</a>, with public repository <a href="https://github.com/pat-jj/Awesome-Adaptation-of-Agentic-AI/tree/main">here</a>. Hope you enjoy reading it!<br>
  <b>[Dec 2025]</b> Honored to receive the <strong>Best Paper Honorable Mention Award</strong> @ NeurIPS LAW Workshop, for our <a href="https://psychology-of-ai.github.io/">Personality Illusion</a> paper.<br>
	<b>[Dec 2025]</b> I am attending NeurIPS 2025 in San Diego, CA, from Dec 2 to Dec 7. Excited to catch up with old and new friends!<br>
	<!-- <b>[Sep 2025]</b> <a href="https://psychology-of-ai.github.io/">The Personality Illusion</a> is accepted to NeurIPS LAW Workshop & NeurIPS PersonaNLP workshop, both as <span style="font-weight:bold; color:red;">Oral Presentations</span>.<br> -->
    <b>[Sep 2025]</b> üî• We released our work discovering <a href="https://psychology-of-ai.github.io/">The Personality Illusion</a>: LLMs do not have personalities in the way humans do.<br>
	  <!-- <b>[Aug. 2025]</b>  <a href="https://openreview.net/forum?id=vn9TiICAui&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3Dcolmweb.org%2FCOLM%2F2025%2FWorkshop%2FINTERPLAY%2FAuthors%23your-submissions)">One paper</a> accepted to <a href="https://interplay-workshop.github.io/">COLM Interplay Workshop</a>.<br> -->
    <!-- <b>[Jul 2025]</b>  Our paper on <a href="https://openreview.net/forum?id=hsgMn4KBFG">LLM Reasoning Failures</a> is accepted to <a href="https://sites.google.com/view/ai4mathworkshopicml2025/">ICML AI for Math Workshop</a>. Stay tuned for our full release!<br> -->
    <!-- <b>[Jun 2025]</b>  Our paper on <a href="https://openreview.net/forum?id=pdLNGgdO1A">Human-Like Traits in LLMs</a> is accepted to <a href="https://sites.google.com/view/mhf-icml2025">ICML MoFA Workshop</a>. Stay tuned for our full release!<br> -->

	  <!-- <b>[July 2025]</b>  <a href="https://openreview.net/forum?id=hsgMn4KBFG">One paper</a> accepted to <a href="https://sites.google.com/view/ai4mathworkshopicml2025/">ICML AI for Math Workshop</a>. Stay tuned for our release!<br>
    <b>[June 2025]</b>  <a href="https://openreview.net/forum?id=pdLNGgdO1A">One paper</a> accepted to <a href="https://sites.google.com/view/mhf-icml2025">ICML Workshop on Models of Human Feedback for AI Alignment</a>. Stay tuned for our release!<br> -->
    <!-- <b>[Apr 2025]</b> I am joining Prof. <a href="https://www.evlab.mit.edu/"> Evelina Fedorenko</a>'s group at MIT starting April 2025, working on the language and thought in LLMs. <br> -->
          <!-- <b>[Apr. 2025]</b> I will begin the MSCS program at UIUC in Fall 2025, where I will continue working with Prof. <a href="https://cs.stanford.edu/~jiaxuan/"> Jiaxuan You</a>. <br> -->
          <!-- <b>[Oct. 2024]</b>  I am attending COLM 2024 to present our paper on<a href="https://arxiv.org/abs/2402.11764"> synthetic data for debiasing</a>. <br>
          <b>[Oct. 2024]</b> Two papers accepted to EMNLP 2024: one in  <a href="https://huggingface.co/spaces/ulab-ai/ArxivCopilot">Demo Track (Paper Copilot)</a>, and one in <a href="https://openreview.net/pdf?id=qu6sMJmEwl">Findings (LLM cognitive errors)</a>.<br> -->
           <!-- <b>[Oct. 2024]</b> Our <a href=" https://huggingface.co/spaces/ulab-ai/ArxivCopilot"> Paper Copilot</a> is accetped to EMNLP 2024 Demo Track.<br>
          <b>[Sep. 2024]</b>  Our paper on <a href="https://openreview.net/pdf?id=qu6sMJmEwl">LLM inhibitory control & A-not-B cognitive errors</a> is accepted to EMNLP 2024 Findings.<br>  -->
          <!-- <b>[July. 2024]</b>  Our paper on<a href="https://arxiv.org/abs/2402.11764"> synthetic data for debiasing</a> is accepted to COLM 2024.<br> -->
          <!-- <b>[May. 2024]</b> We release <a href=" https://huggingface.co/spaces/ulab-ai/ArxivCopilot"> Paper Copilot</a>, an automated research tool for personalized academic service.<br> -->
          <!-- <b>[Apr. 2024]</b> Our paper on  <a href="https://openreview.net/pdf?id=sOSAu0XQcI"> Thought Retriever</a> is accepted to ICLR 2024 Workshop on How Far Are We From AGI.<br> -->
          <!-- <b>[Dec. 2023]</b>  I am joining <a href="https://github.com/ulab-uiuc">UIUC ULab</a>, working on foundation models and intelligent agents<br> -->
            </td>
          </tr>
		
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <!-- <p> I‚Äôm interested in <b>language and intelligence</b> in both humans and machines, particularly the role language plays in shaping intelligent behavior, which I study through comparisons between LLMs and humans. I analyze their behavioral capabilities and failures, examine internal mechanisms, and develop strategies to enhance intelligent machine systems.</p> -->
  <p>
    My research aims to advance <strong><em>scientific understanding of AI (especially neural models like LLMs)</em></strong>, and more broadly, the general principles of intelligence and intelligent behavior. I approach this goal across three interconnected levels:
  </p>

  <ul>
    <li>
      <strong>Behavioral level</strong> &mdash; analyzing how models and humans reason, generalize, and solve problems, including studies of
      <strong><em>alignment, limitations, and trustworthy reasoning</em></strong>.
    </li>
    <li>
      <strong>Mechanistic level</strong> &mdash; interpreting model internals to understand the
      <strong><em>circuits, representations, and algorithms</em></strong> that give rise to intelligent behavior and drive observable performance and failures.
    </li>
    <li>
      <strong>Social level</strong> &mdash; investigating how intelligence emerges and interacts in
      <strong><em>multi-agent systems and human‚ÄìAI collaborations</em></strong>.
    </li>
  </ul>
  One can think of these as three levels, paralleling psychology, neuroscience, and social science in their study of human intelligence and behavior.
  If any of this resonates with your interests, feel free to reach out and let's connect/collaborate!

<!-- <p>In the long run, I am driven by three profound questions:</p>
<ol>
    <li>
        <strong>Understanding the Human Mind:</strong> How can we unravel the complexities of the human mind, cognition, and intelligence? Is it within our reach to recreate these in artificial systems?
    </li>
    <li>
        <strong>Exploring Free Will and Emotions:</strong> Is free will a form of computation? Can we empower machines with human-like qualities such as love, loyalty, and emotions?
    </li>
    <li>
        <strong>The Nature of Reality:</strong> Are we living in a virtual world? Can we model such a world, and what would that mean for our understanding of existence?
    </li>
</ol> -->

<!-- 		      Representative papers are <span class="highlight">highlighted</span>. -->
            </td>
          </tr>
    
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <heading>Selected Publications</heading>

          <tr onmouseout="personality_stop()" onmouseover="personality_start()" id="personality">
            <td style="padding:5px;width:17%;vertical-align:middle">
              <div class="one">
                <div class="two" id='personality_image'>
                  <img src='images/personality-1.png' width="150">
                </div>
                <img src='images/personality-1.png' width="150">
              </div>
              <script type="text/javascript">
                function personality_start() {
                  document.getElementById('personality_image').style.opacity = "1";
                }

                function personality_stop() {
                  document.getElementById('personality_image').style.opacity = "0";
                }
                personality_stop()
              </script>
            </td>
            <td style="padding:20px;width:83%;vertical-align:middle">
              <a target="_blank" href="https://psychology-of-ai.github.io/">
                <papertitle>The Personality Illusion: Revealing Dissociation Between Self-Reports & Behavior in LLMs</papertitle>
              </a>
              <br />
               <strong>Pengrui Han*</strong>, <a target="_blank" href="https://www.rkocielnik.com/">Rafal D. Kocielnik</a>*, <a target="_blank" href="https://peiyang-song.github.io/">Peiyang Song</a>, <a target="_blank" href="https://www.collectivedesign.group.cam.ac.uk/">Ramit Debnath</a>, <a style="text-decoration: none" target="_blank" href="https://www.deanmobbslab.com/people">Dean Mobbs</a>, <a style="text-decoration: none" target="_blank" href="https://www.eas.caltech.edu/people/anima">Anima Anandkumar</a>, and <a style="text-decoration: none" target="_blank" href="https://www.rmichaelalvarez.com/">R. Michael Alvarez</a> (* <strong>Equal Contribution</strong>)
              <br />
              <em>NeurIPS LAW Workshop: Bridging Language, Agent, and World Models</em>, 2025, <font color="red"><strong>Oral Presentation</strong></font> + <font color="red"><strong>Best Paper Honorable Mention </strong></font>
              <br />
              <em>NeurIPS Workshop on LLM Persona Modeling (PersonaNLP)</em>, 2025, <font color="red"><strong>Oral Presentation</strong></font>
              <br />
              <a target="_blank" href="https://arxiv.org/abs/2509.03730">arXiv</a>
              /
              <a target="_blank" href="https://psychology-of-ai.github.io/">project</a>
              /
              <a target="_blank" href="https://github.com/psychology-of-AI/Personality-Illusion">code</a>
              <p></p>
              <p>
                LLMs say they have personalities, but they don‚Äôt act like it. Alignment today shapes language, not behavior. This linguistic‚Äìbehavioral dissociation cautions against equating coherent self-reports with cognitive depth. 
              </p>
            </td>
          </tr>
          
          <tr onmouseout="llmrf_stop()" onmouseover="llmrf_start()" id="llmrf">
            <td style="padding:5px;width:17%;vertical-align:middle">
              <div class="one">
                <div class="two" id='llmrf_image'>
                  <img src='images/llmrf-1.png' width="150">
                </div>
                <img src='images/llmrf-2.png' width="150">
              </div>
              <script type="text/javascript">
                function llmrf_start() {
                  document.getElementById('llmrf_image').style.opacity = "1";
                }

                function llmrf_stop() {
                  document.getElementById('llmrf_image').style.opacity = "0";
                }
                llmrf_stop()
              </script>
            </td>
            <td style="padding:20px;width:83%;vertical-align:middle">
              <a target="_blank" href="https://openreview.net/forum?id=hsgMn4KBFG">
                <papertitle>Large Language Model Reasoning Failures</papertitle>
              </a>
              <br />
              <a target="_blank" href="https://peiyang-song.github.io/">Peiyang Song</a>*, <strong>Pengrui Han</strong>*, and <a target="_blank" href="https://cocolab.stanford.edu/ndg">Noah Goodman</a> (* <strong>Equal Contribution</strong>)
              <br />
              <em>Transactions on Machine Learning Research (TMLR)</em>, 2026 (<font color="red"><strong>Survey Certificate</strong></font>)
              <br />
              <a target="_blank" href="https://openreview.net/forum?id=hsgMn4KBFG">preprint</a>
              /
              full release coming soon
              <p></p>
              <p>
                We present the first comprehensive survey dedicated to reasoning failures in LLMs. By unifying fragmented research efforts, our survey provides a structured perspective on systemic weaknesses in LLM reasoning, offering valuable insights and guiding future research towards building stronger, more reliable, and robust reasoning capabilities.
              </p>
            </td>
          </tr>

          		  <tr onmouseout="adaptation_stop()" onmouseover="adaptation_start()" id="adaptation">
            <td style="padding:5px;width:17%;vertical-align:middle">
              <div class="one">
                <div class="two" id='adaptation_image'>
                  <img src='images/adaptation-1.png' width="150">
                </div>
                <img src='images/adaptation-2.png' width="150">
              </div>
              <script type="text/javascript">
                function adaptation_start() {
                  document.getElementById('adaptation_image').style.opacity = "1";
                }

                function adaptation_stop() {
                  document.getElementById('adaptation_image').style.opacity = "0";
                }
                adaptation_stop()
              </script>
            </td>
            <td style="padding:20px;width:83%;vertical-align:middle">
              <a target="_blank" href="https://arxiv.org/abs/2512.16301">
                <papertitle>Adaptation of Agentic AI</papertitle>
              </a>
              <br />
              <a target="_blank" href="https://pat-jj.github.io/">Pengcheng Jiang</a>*, <a target="_blank" href="https://linjc16.github.io/">Jiacheng Lin</a>*, <a target="_blank" href="https://zhiyiscs.github.io/">Zhiyi Shi</a>*, <a target="_blank" href="https://www.linkedin.com/in/zifengwang-ai">Zifeng Wang</a>, <a target="_blank" href="https://lumos23.github.io/">Luxi He</a>, <a target="_blank" href="https://wuyichen-97.github.io/">Yichen Wu</a>, <a target="_blank" href="https://maszhongming.github.io/">Ming Zhong</a>, <a target="_blank" href="https://peiyang-song.github.io/">Peiyang Song</a>, <a target="_blank" href="https://alex-q-z.github.io/">Qizheng Zhang</a>, <a target="_blank" href="https://arthur-heng.github.io/">Heng Wang</a>, <a target="_blank" href="https://www.linkedin.com/in/xueqiang-xu">Xueqiang Xu</a>, <a target="_blank" href="https://hanwenxuthu.github.io/">Hanwen Xu</a>, <strong>Pengrui Han</strong>, <a target="_blank" href="https://lemon-agreement-54e.notion.site/dylanzhang">Dylan Zhang</a>, <a target="_blank" href="https://gasolsun36.github.io/">Jiashuo Sun</a>, <a target="_blank" href="https://ycq091044.github.io/">Chaoqi Yang</a>, <a target="_blank" href="https://www.linkedin.com/in/kun-qian-7537611aa">Kun Qian</a>, <a target="_blank" href="https://www.linkedin.com/in/tianwng">Tian Wang</a>, <a target="_blank" href="https://www.linkedin.com/in/changran-hu">Changran Hu</a>, <a target="_blank" href="https://limanling.github.io/">Manling Li</a>, <a target="_blank" href="https://researchers.mgh.harvard.edu/profile/4211743/Quanzheng-Li">Quanzheng Li</a>, <a target="_blank" href="https://haopeng-nlp.github.io/">Hao Peng</a>, <a target="_blank" href="https://homes.cs.washington.edu/~swang/">Sheng Wang</a>, <a target="_blank" href="https://shangjingbo1226.github.io/">Jingbo Shang</a>, <a target="_blank" href="http://chaozhang.org/">Chao Zhang</a>, <a target="_blank" href="https://cs.stanford.edu/~jiaxuan/">Jiaxuan You</a>, <a target="_blank" href="https://liyuanlucasliu.github.io/">Liyuan Liu</a>, <a target="_blank" href="https://lupantech.github.io/">Pan Lu</a>, <a target="_blank" href="https://yuzhimanhua.github.io/">Yu Zhang</a>, <a target="_blank" href="https://blender.cs.illinois.edu/hengji.html">Heng Ji</a>, <a target="_blank" href="https://yejinc.github.io/">Yejin Choi</a>, <a target="_blank" href="https://dawnsong.io/">Dawn Song</a>, <a target="_blank" href="https://www.sunlab.org/">Jimeng Sun</a>, <a target="_blank" href="https://hanj.cs.illinois.edu/">Jiawei Han</a> (* Equal Contribution)
              <br />
              <em>Preprint</em>, 2025
              <br />
              <a target="_blank" href="https://arxiv.org/abs/2512.16301">arXiv</a>
              <p></p>
              <p>
                Cutting-edge agentic AI systems are built on foundation models that can be adapted to plan, reason, and interact with external tools to perform increasingly complex and specialized tasks. As these systems grow in capability and scope, adaptation becomes a central mechanism for improving performance, reliability, and generalization. In this paper, we unify the rapidly expanding research landscape into a systematic framework that spans both agent adaptations and tool adaptations.
              </p>
            </td>
          </tr>



          <tr onmouseout="a_not_b_stop()" onmouseover="a_not_b_start()">
            <td style="padding:5px;width:17%;vertical-align:middle">
              <div class="one">
                <div class="two" id='a_not_b_image'>
                  <img src='images/a_not_b-1.jpg' width="150">
                </div>
                <img src='images/a_not_b-2.jpg' width="150">
              </div>
              <script type="text/javascript">
                function a_not_b_start() {
                  document.getElementById('a_not_b_image').style.opacity = "1";
                }

                function a_not_b_stop() {
                  document.getElementById('a_not_b_image').style.opacity = "0";
                }
                a_not_b_stop()
              </script>
            </td>
            <td style="padding:20px;width:83%;vertical-align:middle">
              <a target="_blank" href="https://arxiv.org/abs/2409.15454">
                <papertitle>In-Context Learning May Not Elicit Trustworthy Reasoning: A-Not-B Errors in Pretrained Language Models</papertitle>
              </a>
              <br />
	      <strong>Pengrui Han</strong>*, <a target="_blank" href="https://peiyang-song.github.io/">Peiyang Song</a>*, <a target="_blank" href="https://haofeiyu.me/">Haofei Yu</a>, and <a target="_blank" href="https://cs.stanford.edu/~jiaxuan/">Jiaxuan You</a> (* <strong>Equal Contribution</strong>)
	      <br />
        <em>Findings of Empirical Methods in Natural Language Processing (EMNLP)</em>, 2024
              <br />
	      <a target="_blank" href="https://github.com/Peiyang-Song/LLM-A-Not-B-Errors">code</a>
              <p></p>
              <p>
                Motivated by the crucial cognitive phenomenon of A-not-B errors, we present the first systematic evaluation on the surprisingly vulnerable inhibitory control abilities of LLMs. We reveal that this weakness undermines LLMs' trustworthy reasoning capabilities across diverse domains, and introduce various mitigations.
              </p>
            </td>
          </tr>




          <tr onmouseout="synthetic_stop()" onmouseover="synthetic_start()">
            <td style="padding:5px;width:17%;vertical-align:middle">
              <div class="one">
                <div class="two" id='synthetic_image'>
                  <img src='images/synthetic-1.jpg' width="150" >
                </div>
                <img src='images/synthetic-2.jpg' width="150" >
              </div>
              <script type="text/javascript">
                function synthetic_start() {
                  document.getElementById('synthetic_image').style.opacity = "1";
                }

                function synthetic_stop() {
                  document.getElementById('synthetic_image').style.opacity = "0";
                }
                synthetic_stop()
              </script>
            </td>
            <td style="padding:20px;width:83%;vertical-align:middle">
              <a target="_blank" href="https://arxiv.org/abs/2402.11764">
                <papertitle>ChatGPT Based Data Augmentation for Improved Parameter-Efficient Debiasing of LLMs</papertitle>
              </a>
              <br />
	      <strong>Pengrui Han</strong>*, <a target="_blank" href="https://www.rkocielnik.com/">Rafal Kocielnik</a>*, <a target="_blank" href="https://scholar.google.com/citations?user=rZ53BNsAAAAJ&hl=en&oi=ao">Adhithya Saravanan</a>,<a target="_blank" href="https://www.linkedin.com/in/royjiang2025/">Roy Jiang</a>, <a target="_blank" href="https://sharir.org/">Or Sharir</a>,and <a target="_blank" href="http://tensorlab.cms.caltech.edu/users/anima/">Anima Anandkumar</a> (* <strong>Equal Contribution</strong>)
	      <br />
              <em>Conference On Language Modeling (COLM)</em>, 2024
              <br />
	      <a target="_blank" href="https://github.com/barryhpr/SyntheticDebiasing">code</a>
              <p></p>
              <p>
                We propose a light and efficient pipeline that enables both domain and non-domain experts to quickly generate synthetic debiasing data to mitigate specific or general bias in their models with parameter-efficient fine-tuning.
              </p>
            </td>
          </tr>

          <tr onmouseout="papercopilot_stop()" onmouseover="papercopilot_start()">
            <td style="padding:5px;width:17%;vertical-align:middle">
              <div class="one">
                <div class="two" id='papercopilot_image'>
                  <img src='images/papercopilot-2.png' width="150" >
                </div>
                  <img src='images/papercopilot-1.png' width="150" >
              </div>
              <script type="text/javascript">
                function papercopilot_start() {
                  document.getElementById('papercopilot_image').style.opacity = "1";
                }

                function papercopilot_stop() {
                  document.getElementById('papercopilot_image').style.opacity = "0";
                }
                papercopilot_stop()
              </script>
            </td>
            <td style="padding:20px;width:83%;vertical-align:middle">
              <a target="_blank" href="https://arxiv.org/abs/2409.04593">
                <papertitle>Paper Copilot: A Self-Evolving and Efficient LLM System for Personalized Academic Assistance</papertitle>
              </a>
              <br />
              <a target="_blank" href="https://macenter.wixsite.com/home/guanyulin">Guanyu Lin</a>*, <a target="_blank" href="https://github.com/ft2023">Tao Feng</a>*, <strong>Pengrui Han</strong>*,   <a target="_blank" href="https://www.mit.edu/~geliu/">Ge Liu</a>, <a target="_blank" href="https://cs.stanford.edu/~jiaxuan/">Jiaxuan You</a> (* <strong>Equal Contribution</strong>)
              <br /> <em>System Demonstration Track of Empirical Methods in Natural Language Processing (EMNLP)</em>, 2024<br />
	  
              <em>Huggingface Live Demo: <a target="_blank" href="https://huggingface.co/spaces/ulab-ai/ArxivCopilot">Link</a></em>
 
	      <!-- <a target="_blank" href="https://github.com/barryhpr/SyntheticDebiasing">code</a> -->
              <p></p>
              <p>
                We propose a light and efficient pipeline that enables both domain and non-domain experts to quickly generate synthetic debiasing data to mitigate specific or general bias in their models with parameter-efficient fine-tuning.
              </p>
            </td>
          </tr>

          <!-- <tr onmouseout="tr_stop()" onmouseover="tr_start()">
            <td style="padding:5px;width:17%;vertical-align:middle">
              <div class="one">
                <div class="two" id='tr_image'>
                  <img src='images/tr-2.jpg' width="150" >
                </div>
                <img src='images/tr-1.jpg' width="150" >
              </div>
              <script type="text/javascript">
                function tr_start() {
                  document.getElementById('tr_image').style.opacity = "1";
                }

                function tr_stop() {
                  document.getElementById('tr_image').style.opacity = "0";
                }
                tr_stop()
              </script>
            </td>
            <td style="padding:20px;width:83%;vertical-align:middle">
              <a target="_blank" href="https://openreview.net/pdf?id=sOSAu0XQcI">
                <papertitle>Thought-Retriever: Don‚Äôt Just Retrieve Raw Data,
                  Retrieve Thoughts</papertitle>
              </a>
              <br />
              <a target="_blank" href="https://github.com/ft2023">Tao Feng</a>*, <strong>Pengrui Han</strong>*,  <a target="_blank" href="https://macenter.wixsite.com/home/guanyulin">Guanyu Lin</a>*, <a target="_blank" href="https://www.mit.edu/~geliu/">Ge Liu</a>, <a target="_blank" href="https://cs.stanford.edu/~jiaxuan/">Jiaxuan You</a> (* <strong>Equal Contribution</strong>)
	      <br />
              <em>ICLR Workshop on How Far Are We From AGI</em>, 2024
              <br />
              <p></p>
              <p>
                We introduce <strong>Thought-Retriever</strong> a novel model-agnostic algorithm that enables LLMs to effectively utilize external data without being limited by context length. 
              </p>
            </td>
          </tr> -->

          <!-- <tr onmouseout="pmlr_stop()" onmouseover="pmlr_start()">
            <td style="padding:5px;width:17%;vertical-align:middle">
              <div class="one">
                <div class="two" id='pmlr_image'>
                  <img src='images/pmlr-1.jpg' width="150" >
                </div>
                <img src='images/pmlr-2.jpg' width="150" >
              </div>
              <script type="text/javascript">
                function pmlr_start() {
                  document.getElementById('pmlr_image').style.opacity = "1";
                }

                function pmlr_stop() {
                  document.getElementById('pmlr_image').style.opacity = "0";
                }
                pmlr_stop()
              </script>
            </td>
            <td style="padding:20px;width:83%;vertical-align:middle">
              <a target="_blank" href="https://arxiv.org/pdf/2312.10065">
                <papertitle>Exploring Social Bias in Downstream Applications of
                  Text-to-Image Foundation Models</papertitle>
              </a>
              <br />
              <a target="_blank" href="https://scholar.google.com/citations?user=rZ53BNsAAAAJ&hl=en&oi=ao">Adhithya Saravanan</a>, <a target="_blank" href="https://www.rkocielnik.com/">Rafal Kocielnik</a>, <a target="_blank" href="https://www.linkedin.com/in/royjiang2025/">Roy Jiang</a>, <strong>Pengrui Han</strong>, and <a target="_blank" href="http://tensorlab.cms.caltech.edu/users/anima/">Anima Anandkumar</a> 
	      <br />
          <em>NeurIPS Workshop on Failure Modes in the Age of Foundation Models</em>, 2023 
          <br />
          <em>Proceedings of Machine Learning Research (PMLR)</em>
          <br />

              <p>We explore the social biases in text-to-image diffusion models used in commercial applications like image editing. By analyzing models like Stable Diffusion, we uncover significant biases, emphasizing the need for careful consideration when adopting these technologies for broader use.</p>
              <p>
                
              </p>
            </td>
          </tr> -->

        </tbody></table>

	<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Selected Awards</heading>
		<ul>
      <li>NeurIPS LAW Workshop Best Paper Honorable Mention Award (2025)</li>
      <li>Phi Beta Kappa Honor Society (2025)</li>
		  <li>Carleton College Chang-Lan Award (2024)</li>
		  <li>Caltech SURF Award (2023)</li>
		  <li>Carleton College Dean's List (2023)</li>
		</ul>
            </td>
          </tr>
        </tbody></table>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Selected Media</heading>
		<ul>
      <li><a target="_blank" href="https://venturebeat.com/orchestration/new-framework-simplifies-the-complex-landscape-of-agentic-ai">New Framework Simplifies the Complex Landscape of Agentic AI</a>, VentureBeat, 2025</li>
                <li><a target="_blank" href="https://www.marktechpost.com/2025/12/24/this-ai-paper-from-stanford-and-harvard-explains-why-most-agentic-ai-systems-feel-impressive-in-demos-and-then-completely-fall-apart-in-real-use/">This AI Paper Explains Why Most "Agentic AI" Systems Feel Impressive in Demos and then Completely Fall Apart in Real Use</a>, MarkTechPost, 2025</li>
    
      <li><a target="_blank" href="https://wap.mittrchina.com/news/detail/15459">Researchers Discover "Personality Illusion" to Reveal a Profound Disconnect Between Language and Behavior in LLMs</a>, MIT Technology Review China, 2025</li>

		</ul>
            </td>
          </tr>
        </tbody></table>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Teaching</heading>
		<ul>
    
       <li>CS 512: Data Mining Principles, Teaching Assistant @ UIUC, Fall 2025</li>
       <li>MATH 241: Ordinary Differential Equations, Teaching Assistant @ Carleton College, Fall 2024</li>
      <li>MATH 321: Real Analysis, Teaching Assistant @ Carleton College, Spring 2024</li>
      <li>MATH 232: Linear Algebra, Teaching Assistant @ Carleton College, Spring 2023</li>
      <li>MATH 232: Linear Algebra, Teaching Assistant @ Carleton College, Winter 2023</li>


		</ul>
            </td>
          </tr>
        </tbody></table>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Academic Services</heading>
		<ul>
		  <li><b>Reviewer for conferences:</b> ICLR, ICML, COLM, COLING.</li>
		  <li><b>Reviewer for workshops:</b> Re-Align, LLM-Cognition, BehaviorML, LTEDI, INTERPLAY, AI4Math, LatinX, Assessing World Models</li>
		</ul>
            </td>
          </tr>
        </tbody></table>

	      
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br />
              <p style="text-align:right;font-size:small;">
                <a target="_blank" href="https://jonbarron.info/" style="text-align:right;font-size:small;">Site source</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>

</body>

</html>

